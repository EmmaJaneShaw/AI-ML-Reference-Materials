Daitaku/Oreilly Techniques for Responsible AI https://content.dataiku.com/machine-learning-high-risk-applications/oreilly-responsible-ai?utm_campaign=CONTENT+Nurturing+Workflows+2022&utm_medium=email&_hsmi=210483111&_hsenc=p2ANqtz-8B716qXCuj2KDmWn4Sowp4OKSYbxIBqGjBUDiVSsbkCE5ba7NXAtqnbygyXi_-kTfHMEBsDABif0bGUavi2Qm9Zt6V_Ku-V0jSNNKqUEFe7NVCKSc&utm_content=210483111&utm_source=hs_automation

Hooker et al 2021 'There Is No Free Variable Importance': https://arxiv.org/pdf/1905.03151.pdf
Bastani et al 2018 'Interpretability via Model Extraction': https://arxiv.org/pdf/1706.09773.pdf
Rebiero et al 2018 '“Why Should I Trust You?” Explaining the Predictions of Any Classifier': https://arxiv.org/pdf/1602.04938.pdf
Broniatowski 2021 'Psychological Foundations of Explainability and Interpretability in Artificial Intelligence': https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8367.pdf
Rudin 2019 'Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead': https://arxiv.org/pdf/1811.10154.pdf
Agarwal et al 2018 'Neural Additive Models:Interpretable Machine Learning with Neural Nets': https://arxiv.org/pdf/2004.13912.pdf
Molnar 2021 'Interpretable Machine Learning A Guide for Making Black Box Models Explainable' https://christophm.github.io/interpretable-ml-book/
